## Cloud Dataproc - Supercomputing Platform
Hadoop is a supercomputing platform consisting of HDFS for distributed storage of data and YARN for scheduling parallel processing jobs

Hadoop follows a programming model called MapReduce where
- "Map" function runs in parallel with a massive data set to produce intermediate results and
- "Reduce" function builds a final result set based on all the intermediate results
### Cloud Dataproc is managed Hadoop
- Dataproc is fast, and managed way to run Hadoop along with Spark/Hive/Pig on GCP
- Easily scalable even when jobs are running
